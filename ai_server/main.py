"""
AI Server - Vietnamese Food Recognition
FastAPI server ƒë·ªÉ serve AI model nh·∫≠n di·ªán m√≥n ƒÉn
"""
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import uvicorn

from config import settings
from model import get_classifier


# Pydantic models for response
class PredictionItem(BaseModel):
    label: str
    confidence: float
    rank: int


class PredictionResponse(BaseModel):
    success: bool
    predictions: List[PredictionItem]
    message: Optional[str] = None
    note: Optional[str] = None


class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    framework: str
    labels_count: int


# Create FastAPI app
app = FastAPI(
    title="Vietnamese Food Recognition AI",
    description="AI API ƒë·ªÉ nh·∫≠n di·ªán m√≥n ƒÉn Vi·ªát Nam t·ª´ h√¨nh ·∫£nh",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    """Load model khi server start"""
    print("üöÄ Starting AI Server...")
    classifier = get_classifier()
    print(f"‚úì Model loaded: {classifier.framework}")
    print(f"‚úì Labels: {len(classifier.labels)}")


@app.get("/", response_model=dict)
async def root():
    """Root endpoint"""
    return {
        "message": "Vietnamese Food Recognition AI Server",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    classifier = get_classifier()
    return HealthResponse(
        status="healthy",
        model_loaded=classifier.model is not None or classifier.framework == 'mock',
        framework=classifier.framework,
        labels_count=len(classifier.labels)
    )


@app.post("/predict", response_model=PredictionResponse)
async def predict(file: UploadFile = File(...)):
    """
    Nh·∫≠n di·ªán m√≥n ƒÉn t·ª´ h√¨nh ·∫£nh
    
    - **file**: File h√¨nh ·∫£nh (JPG, PNG, WEBP)
    
    Returns:
        Danh s√°ch predictions v·ªõi label v√† confidence
    """
    # Validate file type
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=400,
            detail="File ph·∫£i l√† h√¨nh ·∫£nh (JPG, PNG, WEBP)"
        )
    
    # Read file
    contents = await file.read()
    
    # Check file size (max 10MB)
    if len(contents) > 10 * 1024 * 1024:
        raise HTTPException(
            status_code=400,
            detail="File qu√° l·ªõn. T·ªëi ƒëa 10MB"
        )
    
    # Get prediction
    classifier = get_classifier()
    result = classifier.predict(contents)
    
    if not result['success']:
        raise HTTPException(
            status_code=500,
            detail=result.get('error', 'Prediction failed')
        )
    
    return PredictionResponse(
        success=True,
        predictions=[
            PredictionItem(**pred) for pred in result['predictions']
        ],
        message=f"ƒê√£ nh·∫≠n di·ªán {len(result['predictions'])} m√≥n ƒÉn",
        note=result.get('note')
    )


@app.get("/labels")
async def get_labels():
    """
    L·∫•y danh s√°ch c√°c nh√£n m√≥n ƒÉn model c√≥ th·ªÉ nh·∫≠n di·ªán
    """
    classifier = get_classifier()
    return {
        "total": len(classifier.labels),
        "labels": classifier.labels
    }


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG
    )
